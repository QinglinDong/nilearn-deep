{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dictionary Learning and ICA for doing group analysis of resting-state fMRI\n",
    "==========================================================================\n",
    "\n",
    "This example applies dictionary learning and ICA to resting-state data,\n",
    "visualizing resulting components using atlas plotting tools.\n",
    "\n",
    "Dictionary learning is a sparsity based decomposition method for extracting\n",
    "spatial maps. It extracts maps that are naturally sparse and usually cleaner\n",
    "than ICA\n",
    "\n",
    "   * Arthur Mensch et al. `Compressed online dictionary learning for fast resting-state fMRI decomposition\n",
    "     <https://hal.archives-ouvertes.fr/hal-01271033/>`_,\n",
    "     ISBI 2016, Lecture Notes in Computer Science\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The use of the attribute `components_img_` from decomposition\n",
    "    estimators is implemented from version 0.4.1.\n",
    "    For older versions, unmask the deprecated attribute `components_` to\n",
    "    get the components image using attribute `masker_` embedded in estimator.\n",
    "    See the `section Inverse transform: unmasking data <unmasking_step>`.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ADHD rest dataset\n",
    "-----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First functional nifti image (4D) is at: /home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/datasets/func.py:503: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  dtype=None)\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "adhd_dataset = datasets.fetch_adhd(n_subjects=30,data_dir='/home/share/TmpData/Qinglin/nilearn_data/')\n",
    "func_filenames = adhd_dataset.func  # list of 4D nifti files for each subject\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('First functional nifti image (4D) is at: %s' %\n",
    "      adhd_dataset.func[0])  # 4D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two decomposition estimators\n",
    "------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decomposition import DictLearning, CanICA\n",
    "\n",
    "n_components = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary learning\n",
    "--------------------\n",
    "\n",
    "We use as \"template\" as a strategy to compute the mask, as this leads\n",
    "to slightly faster and more reproducible results. However, the images\n",
    "need to be in MNI template space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_learning = DictLearning(n_components=n_components,\n",
    "                             memory=\"nilearn_cache\", memory_level=2,\n",
    "                             verbose=1,\n",
    "                             random_state=0,\n",
    "                             n_epochs=1,\n",
    "                             mask_strategy='epi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CanICA\n",
    "------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canica = CanICA(n_components=n_components,\n",
    "                memory=\"nilearn_cache\", memory_level=2,\n",
    "                threshold=3.,\n",
    "                n_init=1,\n",
    "                verbose=1,\n",
    "                mask_strategy='epi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit both estimators\n",
    "--------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Example] Learning maps using DictionaryLearning model\n",
      "[MultiNiftiMasker.fit] Loading data from [/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz, /home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.g\n",
      "[MultiNiftiMasker.fit] Computing mask\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[DictLearning] Loading data\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010128/0010128_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010128/0010128_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0021019/0021019_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0021019/0021019_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0023008/0023008_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0023008/0023008_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0023012/0023012_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0023012/0023012_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027011/0027011_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027011/0027011_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027018/0027018_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027018/0027018_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027034/0027034_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027034/0027034_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027037/0027037_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027037/0027037_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1019436/1019436_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1019436/1019436_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1206380/1206380_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1206380/1206380_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1418396/1418396_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1418396/1418396_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1517058/1517058_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1517058/1517058_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1552181/1552181_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1552181/1552181_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1562298/1562298_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1562298/1562298_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n"
     ]
    }
   ],
   "source": [
    "estimators = [dict_learning, canica]\n",
    "names = {dict_learning: 'DictionaryLearning', canica: 'CanICA'}\n",
    "components_imgs = []\n",
    "\n",
    "for estimator in estimators:\n",
    "    print('[Example] Learning maps using %s model' % names[estimator])\n",
    "    estimator.fit(func_filenames)\n",
    "    print('[Example] Saving results')\n",
    "    # Grab extracted components umasked back to Nifti image.\n",
    "    # Note: For older versions, less than 0.4.1. components_img_\n",
    "    # is not implemented. See Note section above for details.\n",
    "    components_img = estimator.components_img_\n",
    "    components_img.to_filename('%s_resting_state.nii.gz' %\n",
    "                               names[estimator])\n",
    "    components_imgs.append(components_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results\n",
    "----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import (plot_prob_atlas, find_xyz_cut_coords, show,\n",
    "                              plot_stat_map)\n",
    "from nilearn.image import index_img\n",
    "\n",
    "# Selecting specific maps to display: maps were manually chosen to be similar\n",
    "indices = {dict_learning: 25, canica: 33}\n",
    "# We select relevant cut coordinates for displaying\n",
    "cut_component = index_img(components_imgs[0], indices[dict_learning])\n",
    "cut_coords = find_xyz_cut_coords(cut_component)\n",
    "for estimator, components in zip(estimators, components_imgs):\n",
    "    # 4D plotting\n",
    "    plot_prob_atlas(components, view_type=\"filled_contours\",\n",
    "                    title=\"%s\" % names[estimator],\n",
    "                    cut_coords=cut_coords, colorbar=False)\n",
    "    # 3D plotting\n",
    "    plot_stat_map(index_img(components, indices[estimator]),\n",
    "                  title=\"%s\" % names[estimator],\n",
    "                  cut_coords=cut_coords, colorbar=False)\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
