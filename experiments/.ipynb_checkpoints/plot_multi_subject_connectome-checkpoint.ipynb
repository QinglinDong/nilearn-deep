{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Group Sparse inverse covariance for multi-subject connectome\n",
    "=============================================================\n",
    "\n",
    "This example shows how to estimate a connectome on a group of subjects\n",
    "using the group sparse inverse covariance estimate.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nilearn import plotting\n",
    "\n",
    "n_subjects = 4  # subjects to consider for group-sparse covariance (max: 40)\n",
    "\n",
    "\n",
    "def plot_matrices(cov, prec, title, labels):\n",
    "    \"\"\"Plot covariance and precision matrices, for a given processing. \"\"\"\n",
    "\n",
    "    prec = prec.copy()  # avoid side effects\n",
    "\n",
    "    # Put zeros on the diagonal, for graph clarity.\n",
    "    size = prec.shape[0]\n",
    "    prec[list(range(size)), list(range(size))] = 0\n",
    "    span = max(abs(prec.min()), abs(prec.max()))\n",
    "\n",
    "    # Display covariance matrix\n",
    "    plotting.plot_matrix(cov, cmap=plotting.cm.bwr,\n",
    "                         vmin=-1, vmax=1, title=\"%s / covariance\" % title,\n",
    "                         labels=labels)\n",
    "    # Display precision matrix\n",
    "    plotting.plot_matrix(prec, cmap=plotting.cm.bwr,\n",
    "                         vmin=-span, vmax=span, title=\"%s / precision\" % title,\n",
    "                         labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching datasets\n",
    "------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First subject functional nifti image (4D) is at: /home/uga_qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.py:2278: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n",
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/datasets/func.py:502: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  dtype=None)\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "msdl_atlas_dataset = datasets.fetch_atlas_msdl()\n",
    "adhd_dataset = datasets.fetch_adhd(n_subjects=n_subjects)\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('First subject functional nifti image (4D) is at: %s' %\n",
    "      adhd_dataset.func[0])  # 4D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting region signals\n",
    "--------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMapsMasker.fit] loading regions from /home/uga_qinglin/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii\n",
      "Processing file /home/uga_qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.image.image.high_variance_confounds...\n",
      "high_variance_confounds('/home/uga_qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________high_variance_confounds - 2.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.base_masker.filter_and_extract...\n",
      "filter_and_extract('/home/uga_qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz', \n",
      "<nilearn.input_data.nifti_maps_masker._ExtractionFunctor object at 0x7f5e9407e350>, \n",
      "{ 'allow_overlap': True,\n",
      "  'detrend': True,\n",
      "  'high_pass': 0.01,\n",
      "  'low_pass': None,\n",
      "  'maps_img': '/home/uga_qinglin/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',\n",
      "  'mask_img': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': True,\n",
      "  't_r': 2.5,\n",
      "  'target_affine': array([[   4.,    0.,    0.,  -78.],\n",
      "       [   0.,    4.,    0., -111.],\n",
      "       [   0.,    0.,    4.,  -51.],\n",
      "       [   0.,    0.,    0.,    1.]]),\n",
      "  'target_shape': (40, 48, 35)}, confounds=[ array([[-0.018015, ...,  0.103569],\n",
      "       ...,\n",
      "       [ 0.001785, ..., -0.031497]], dtype=float32),\n",
      "  '/home/uga_qinglin/nilearn_data/adhd/data/0010042/0010042_regressors.csv'], memory_level=1, verbose=2, memory=Memory(location=nilearn_cache/joblib))\n",
      "[NiftiMapsMasker.transform_single_imgs] Loading data from /home/uga_qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[NiftiMapsMasker.transform_single_imgs] Resampling images\n",
      "[NiftiMapsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "_______________________________________________filter_and_extract - 7.1s, 0.1min\n",
      "Processing file /home/uga_qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.image.image.high_variance_confounds...\n",
      "high_variance_confounds('/home/uga_qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________high_variance_confounds - 2.2s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.base_masker.filter_and_extract...\n",
      "filter_and_extract('/home/uga_qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz', \n",
      "<nilearn.input_data.nifti_maps_masker._ExtractionFunctor object at 0x7f5e9c6bcd10>, \n",
      "{ 'allow_overlap': True,\n",
      "  'detrend': True,\n",
      "  'high_pass': 0.01,\n",
      "  'low_pass': None,\n",
      "  'maps_img': '/home/uga_qinglin/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',\n",
      "  'mask_img': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': True,\n",
      "  't_r': 2.5,\n",
      "  'target_affine': array([[   4.,    0.,    0.,  -78.],\n",
      "       [   0.,    4.,    0., -111.],\n",
      "       [   0.,    0.,    4.,  -51.],\n",
      "       [   0.,    0.,    0.,    1.]]),\n",
      "  'target_shape': (40, 48, 35)}, confounds=[ array([[-0.129865, ..., -0.043024],\n",
      "       ...,\n",
      "       [-0.03078 , ..., -0.122373]], dtype=float32),\n",
      "  '/home/uga_qinglin/nilearn_data/adhd/data/0010064/0010064_regressors.csv'], memory_level=1, verbose=2, memory=Memory(location=nilearn_cache/joblib))\n",
      "[NiftiMapsMasker.transform_single_imgs] Loading data from /home/uga_qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[NiftiMapsMasker.transform_single_imgs] Resampling images\n",
      "[NiftiMapsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "_______________________________________________filter_and_extract - 7.1s, 0.1min\n",
      "Processing file /home/uga_qinglin/nilearn_data/adhd/data/0010128/0010128_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.image.image.high_variance_confounds...\n",
      "high_variance_confounds('/home/uga_qinglin/nilearn_data/adhd/data/0010128/0010128_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "__________________________________________high_variance_confounds - 2.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.base_masker.filter_and_extract...\n",
      "filter_and_extract('/home/uga_qinglin/nilearn_data/adhd/data/0010128/0010128_rest_tshift_RPI_voreg_mni.nii.gz', \n",
      "<nilearn.input_data.nifti_maps_masker._ExtractionFunctor object at 0x7f5e9c6bcd10>, \n",
      "{ 'allow_overlap': True,\n",
      "  'detrend': True,\n",
      "  'high_pass': 0.01,\n",
      "  'low_pass': None,\n",
      "  'maps_img': '/home/uga_qinglin/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',\n",
      "  'mask_img': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': True,\n",
      "  't_r': 2.5,\n",
      "  'target_affine': array([[   4.,    0.,    0.,  -78.],\n",
      "       [   0.,    4.,    0., -111.],\n",
      "       [   0.,    0.,    4.,  -51.],\n",
      "       [   0.,    0.,    0.,    1.]]),\n",
      "  'target_shape': (40, 48, 35)}, confounds=[ array([[0.017256, ..., 0.040763],\n",
      "       ...,\n",
      "       [0.024104, ..., 0.018105]], dtype=float32),\n",
      "  '/home/uga_qinglin/nilearn_data/adhd/data/0010128/0010128_regressors.csv'], memory_level=1, verbose=2, memory=Memory(location=nilearn_cache/joblib))\n",
      "[NiftiMapsMasker.transform_single_imgs] Loading data from /home/uga_qinglin/nilearn_data/adhd/data/0010128/0010128_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[NiftiMapsMasker.transform_single_imgs] Resampling images\n",
      "[NiftiMapsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "_______________________________________________filter_and_extract - 7.1s, 0.1min\n",
      "Processing file /home/uga_qinglin/nilearn_data/adhd/data/0021019/0021019_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.image.image.high_variance_confounds...\n",
      "high_variance_confounds('/home/uga_qinglin/nilearn_data/adhd/data/0021019/0021019_rest_tshift_RPI_voreg_mni.nii.gz')\n",
      "__________________________________________high_variance_confounds - 2.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.base_masker.filter_and_extract...\n",
      "filter_and_extract('/home/uga_qinglin/nilearn_data/adhd/data/0021019/0021019_rest_tshift_RPI_voreg_mni.nii.gz', \n",
      "<nilearn.input_data.nifti_maps_masker._ExtractionFunctor object at 0x7f5e438dbe90>, \n",
      "{ 'allow_overlap': True,\n",
      "  'detrend': True,\n",
      "  'high_pass': 0.01,\n",
      "  'low_pass': None,\n",
      "  'maps_img': '/home/uga_qinglin/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',\n",
      "  'mask_img': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': True,\n",
      "  't_r': 2.5,\n",
      "  'target_affine': array([[   4.,    0.,    0.,  -78.],\n",
      "       [   0.,    4.,    0., -111.],\n",
      "       [   0.,    0.,    4.,  -51.],\n",
      "       [   0.,    0.,    0.,    1.]]),\n",
      "  'target_shape': (40, 48, 35)}, confounds=[ array([[ 0.038218, ..., -0.021777],\n",
      "       ...,\n",
      "       [ 0.063512, ...,  0.081868]], dtype=float32),\n",
      "  '/home/uga_qinglin/nilearn_data/adhd/data/0021019/0021019_regressors.csv'], memory_level=1, verbose=2, memory=Memory(location=nilearn_cache/joblib))\n",
      "[NiftiMapsMasker.transform_single_imgs] Loading data from /home/uga_qinglin/nilearn_data/adhd/data/0021019/0021019_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "[NiftiMapsMasker.transform_single_imgs] Resampling images\n",
      "[NiftiMapsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "_______________________________________________filter_and_extract - 7.1s, 0.1min\n"
     ]
    }
   ],
   "source": [
    "from nilearn import image\n",
    "from nilearn import input_data\n",
    "\n",
    "# A \"memory\" to avoid recomputation\n",
    "from sklearn.externals.joblib import Memory\n",
    "mem = Memory('nilearn_cache')\n",
    "\n",
    "masker = input_data.NiftiMapsMasker(\n",
    "    msdl_atlas_dataset.maps, resampling_target=\"maps\", detrend=True,\n",
    "    low_pass=None, high_pass=0.01, t_r=2.5, standardize=True,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=2)\n",
    "masker.fit()\n",
    "\n",
    "subject_time_series = []\n",
    "func_filenames = adhd_dataset.func\n",
    "confound_filenames = adhd_dataset.confounds\n",
    "for func_filename, confound_filename in zip(func_filenames,\n",
    "                                            confound_filenames):\n",
    "    print(\"Processing file %s\" % func_filename)\n",
    "\n",
    "    # Computing some confounds\n",
    "    hv_confounds = mem.cache(image.high_variance_confounds)(\n",
    "        func_filename)\n",
    "\n",
    "    region_ts = masker.transform(func_filename,\n",
    "                                 confounds=[hv_confounds, confound_filename])\n",
    "    subject_time_series.append(region_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing group-sparse precision matrices\n",
    "------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 4\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 6\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 2\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 2\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 4\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 6\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  2 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 2\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 4\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 4\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 7\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3\n",
      "[GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  3 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 7\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0\n",
      "[GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  4 out of 4\n",
      "[GroupSparseCovarianceCV.fit] Final optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GroupSparseCovarianceCV.fit] tolerance reached at iteration number 14: 9.775e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class GraphLassoCV is deprecated; The 'GraphLassoCV' was renamed to 'GraphicalLassoCV' in version 0.20 and will be removed in 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "....[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "........[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GraphicalLassoCV] Done refinement  1 out of 4:   1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "........[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GraphicalLassoCV] Done refinement  2 out of 4:   2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "........[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GraphicalLassoCV] Done refinement  3 out of 4:   3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "........[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GraphicalLassoCV] Done refinement  4 out of 4:   4s\n",
      "[graphical_lasso] Iteration   0, cost  1.71e+02, dual gap 7.980e-01\n",
      "[graphical_lasso] Iteration   1, cost  1.71e+02, dual gap 9.174e-03\n",
      "[graphical_lasso] Iteration   2, cost  1.71e+02, dual gap 1.086e-03\n",
      "[graphical_lasso] Iteration   3, cost  1.71e+02, dual gap 1.496e-04\n",
      "[graphical_lasso] Iteration   4, cost  1.71e+02, dual gap 2.871e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphLassoCV(alphas=4, assume_centered=False, cv='warn', enet_tol=0.0001,\n",
       "       max_iter=100, mode='cd', n_jobs=None, n_refinements=4, tol=0.0001,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nilearn.connectome import GroupSparseCovarianceCV\n",
    "gsc = GroupSparseCovarianceCV(verbose=2)\n",
    "gsc.fit(subject_time_series)\n",
    "\n",
    "from sklearn import covariance\n",
    "gl = covariance.GraphLassoCV(verbose=2)\n",
    "gl.fit(np.concatenate(subject_time_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying results\n",
    "-------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'find_probabilistic_atlas_cut_coords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d70210d52d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0matlas_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsdl_atlas_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0matlas_region_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_probabilistic_atlas_cut_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matlas_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsdl_atlas_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m plotting.plot_connectome(gl.covariance_,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'find_probabilistic_atlas_cut_coords'"
     ]
    }
   ],
   "source": [
    "atlas_img = msdl_atlas_dataset.maps\n",
    "atlas_region_coords = plotting.find_probabilistic_atlas_cut_coords(atlas_img)\n",
    "labels = msdl_atlas_dataset.labels\n",
    "\n",
    "plotting.plot_connectome(gl.covariance_,\n",
    "                         atlas_region_coords, edge_threshold='90%',\n",
    "                         title=\"Covariance\",\n",
    "                         display_mode=\"lzr\")\n",
    "plotting.plot_connectome(-gl.precision_, atlas_region_coords,\n",
    "                         edge_threshold='90%',\n",
    "                         title=\"Sparse inverse covariance (GraphLasso)\",\n",
    "                         display_mode=\"lzr\",\n",
    "                         edge_vmax=.5, edge_vmin=-.5)\n",
    "plot_matrices(gl.covariance_, gl.precision_, \"GraphLasso\", labels)\n",
    "\n",
    "title = \"GroupSparseCovariance\"\n",
    "plotting.plot_connectome(-gsc.precisions_[..., 0],\n",
    "                         atlas_region_coords, edge_threshold='90%',\n",
    "                         title=title,\n",
    "                         display_mode=\"lzr\",\n",
    "                         edge_vmax=.5, edge_vmin=-.5)\n",
    "plot_matrices(gsc.covariances_[..., 0],\n",
    "              gsc.precisions_[..., 0], title, labels)\n",
    "\n",
    "plotting.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
