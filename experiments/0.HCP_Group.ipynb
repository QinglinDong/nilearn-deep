{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "(3600, 228453)\n",
      "RELATIONAL\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "(4692, 228453)\n",
      "SOCIAL\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "(5500, 228453)\n",
      "WM\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "(8100, 228453)\n",
      "GAMBLING\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "(5099, 228453)\n",
      "LANGUAGE\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n"
     ]
    },
    {
     "ename": "JoblibIOError",
     "evalue": "JoblibIOError\n___________________________________________________________________________\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f54e43b48b0, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f54e43b48b0, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    494         if self.poller is not None:\n    495             self.poller.start()\n    496         self.kernel.start()\n    497         self.io_loop = ioloop.IOLoop.current()\n    498         try:\n--> 499             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    500         except KeyboardInterrupt:\n    501             pass\n    502 \n    503 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n   1068                 self._events.update(event_pairs)\n   1069                 while self._events:\n   1070                     fd, events = self._events.popitem()\n   1071                     try:\n   1072                         fd_obj, handler_func = self._handlers[fd]\n-> 1073                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n   1074                     except (OSError, IOError) as e:\n   1075                         if errno_from_exception(e) == errno.EPIPE:\n   1076                             # Happens when the client closes the connection\n   1077                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 10, 20, 14, 38, 46, 279769, tzinfo=tzutc()), u'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', u'msg_type': u'execute_request', u'session': u'e59763e82f0e40db8130b18fb5b3ce95', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['e59763e82f0e40db8130b18fb5b3ce95']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 10, 20, 14, 38, 46, 279769, tzinfo=tzutc()), u'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', u'msg_type': u'execute_request', u'session': u'e59763e82f0e40db8130b18fb5b3ce95', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['e59763e82f0e40db8130b18fb5b3ce95'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 10, 20, 14, 38, 46, 279769, tzinfo=tzutc()), u'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', u'msg_type': u'execute_request', u'session': u'e59763e82f0e40db8130b18fb5b3ce95', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', store_history=True, silent=False, shell_futures=True)\n   2709                 self.displayhook.exec_result = result\n   2710 \n   2711                 # Execute the user code\n   2712                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2713                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2714                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2715                 \n   2716                 self.last_execution_succeeded = not has_raised\n   2717 \n   2718                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Import object>, <_ast.Assign object>, <_ast.If object>, <_ast.ImportFrom object>, <_ast.For object>], cell_name='<ipython-input-1-63ea1ef337ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f54dc257ed0, executi..._before_exec=None error_in_exec=None result=None>)\n   2813 \n   2814         try:\n   2815             for i, node in enumerate(to_run_exec):\n   2816                 mod = ast.Module([node])\n   2817                 code = compiler(mod, cell_name, \"exec\")\n-> 2818                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f54dc2561b0, file \"<ipython-input-1-63ea1ef337ba>\", line 12>\n        result = <ExecutionResult object at 7f54dc257ed0, executi..._before_exec=None error_in_exec=None result=None>\n   2819                     return True\n   2820 \n   2821             for i, node in enumerate(to_run_interactive):\n   2822                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f54dc2561b0, file \"<ipython-input-1-63ea1ef337ba>\", line 12>, result=<ExecutionResult object at 7f54dc257ed0, executi..._before_exec=None error_in_exec=None result=None>)\n   2873         outflag = 1  # happens in more places, so it's easier as default\n   2874         try:\n   2875             try:\n   2876                 self.hooks.pre_run_code_hook()\n   2877                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2878                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f54dc2561b0, file \"<ipython-input-1-63ea1ef337ba>\", line 12>\n        self.user_global_ns = {'CanICA': <class 'nilearn.decomposition.canica.CanICA'>, 'In': ['', u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...share/TmpData/Qinglin/nilearn_cache\\')\\n        '], 'Out': {}, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__name__': '__main__', ...}\n        self.user_ns = {'CanICA': <class 'nilearn.decomposition.canica.CanICA'>, 'In': ['', u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...share/TmpData/Qinglin/nilearn_cache\\')\\n        '], 'Out': {}, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__name__': '__main__', ...}\n   2879             finally:\n   2880                 # Reset our crash handler in place\n   2881                 sys.excepthook = old_excepthook\n   2882         except SystemExit as e:\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/experiments/<ipython-input-1-63ea1ef337ba> in <module>()\n     19             func_filenames.append(file)   \n     20     func_filenames=func_filenames[:100]\n     21     canica = CanICA(n_components=40, mask=mask_img, smoothing_fwhm=6.,\n     22                 memory=\"/home/share/TmpData/Qinglin/nilearn_cache\", memory_level=2,\n     23                 threshold=3., verbose=10, random_state=0,n_jobs=8)\n---> 24     data=canica.prepare_data(func_filenames, reduction_ratio=0.2)\n     25     print(data.shape)\n     26 \n     27     import numpy as np\n     28     np.save('/home/share/TmpData/Qinglin/HCP_Group/'+t+'100_0.2.npy', data)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py in prepare_data(self=CanICA(detrend=True, do_cca=True, high_pass=None...    target_shape=None, threshold=3.0, verbose=10), imgs=['/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/183337/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/181636/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/751348/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/102816/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/179548/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/268749/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/686969/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/170631/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/144125/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/341834/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/134425/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/130417/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/173839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/156233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/122620/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/433839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/129028/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/139233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/178647/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ...], y=None, confounds=None, reduction_ratio=0.2)\n    407             reduction_ratio=reduction_ratio,\n    408             n_components=self.n_components,\n    409             random_state=self.random_state,\n    410             memory=self.memory,\n    411             memory_level=max(0, self.memory_level + 1),\n--> 412             n_jobs=self.n_jobs)\n        self.n_jobs = 8\n    413         return data\n    414 \n    415     def fit(self, imgs, y=None, confounds=None):\n    416         data= self.prepare_data(imgs, y, confounds)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py in mask_and_reduce(masker=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), imgs=['/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/183337/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/181636/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/751348/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/102816/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/179548/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/268749/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/686969/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/170631/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/144125/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/341834/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/134425/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/130417/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/173839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/156233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/122620/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/433839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/129028/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/139233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/178647/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ...], confounds=repeat(None), reduction_ratio=0.2, n_components=40, random_state=0, memory_level=3, memory='/home/share/TmpData/Qinglin/nilearn_cache', n_jobs=8)\n    173             reduction_ratio=reduction_ratio,\n    174             n_samples=n_samples,\n    175             memory=memory,\n    176             memory_level=memory_level,\n    177             random_state=random_state\n--> 178         ) for img, confound in zip(imgs, confounds))\n        imgs = ['/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/183337/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/181636/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/751348/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/102816/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/179548/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/268749/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/686969/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/170631/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/144125/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/341834/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/134425/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/130417/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/173839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/156233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/122620/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/433839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/129028/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/139233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/178647/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ...]\n        confounds = repeat(None)\n    179 \n    180     subject_n_samples = [subject_data.shape[0]\n    181                          for subject_data in data_list]\n    182 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    991                 # No need to wait for async callbacks to trigger to\n    992                 # consumption.\n    993                 self._iterating = False\n    994 \n    995             with self._backend.retrieval_context():\n--> 996                 self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    997             # Make sure that we get a last message telling us we are done\n    998             elapsed_time = time.time() - self._start_time\n    999             self._print('Done %3i out of %3i | elapsed: %s finished',\n   1000                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nJoblib worker traceback:\n---------------------------------------------------------------------------\nIOError                                            Sat Oct 20 12:18:16 2018\nPID: 20361                                   Python 2.7.12: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    256         self._pickle_cache = pickle_cache if pickle_cache is not None else {}\n    257 \n    258     def __call__(self):\n    259         with parallel_backend(self._backend):\n    260             return [func(*args, **kwargs)\n--> 261                     for func, args, kwargs in self.items]\n        func = <function _mask_and_reduce_single>\n        args = [MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', None]\n        kwargs = {'memory': '/home/share/TmpData/Qinglin/nilearn_cache', 'memory_level': 3, 'n_samples': None, 'random_state': 0, 'reduction_ratio': 0.2}\n        self.items = [(<function _mask_and_reduce_single>, [MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', None], {'memory': '/home/share/TmpData/Qinglin/nilearn_cache', 'memory_level': 3, 'n_samples': None, 'random_state': 0, 'reduction_ratio': 0.2})]\n    262 \n    263     def __len__(self):\n    264         return self._size\n    265 \n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py in _mask_and_reduce_single(masker=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), img='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', confound=None, reduction_ratio=0.2, n_samples=None, memory='/home/share/TmpData/Qinglin/nilearn_cache', memory_level=3, random_state=0)\n    203                             n_samples=None,\n    204                             memory=None,\n    205                             memory_level=0,\n    206                             random_state=None):\n    207     \"\"\"Utility function for multiprocessing from MaskReducer\"\"\"\n--> 208     this_data = masker.transform(img, confound)\n        this_data = undefined\n        masker.transform = <bound method MultiNiftiMasker.transform of Mult...rget_affine=None, target_shape=None, verbose=10)>\n        img = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n        confound = None\n    209     # Now get rid of the img as fast as possible, to free a\n    210     # reference count on it, and possibly free the corresponding\n    211     # data\n    212     del img\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/input_data/multi_nifti_masker.py in transform(self=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), imgs='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', confounds=None)\n    303             preprocessed images\n    304         \"\"\"\n    305         self._check_fitted()\n    306         if not hasattr(imgs, '__iter__') \\\n    307                 or isinstance(imgs, _basestring):\n--> 308             return self.transform_single_imgs(imgs)\n        self.transform_single_imgs = <bound method MultiNiftiMasker.transform_single_...rget_affine=None, target_shape=None, verbose=10)>\n        imgs = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n    309         return self.transform_imgs(imgs, confounds, n_jobs=self.n_jobs)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/input_data/nifti_masker.py in transform_single_imgs(self=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), imgs='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', confounds=None, copy=True)\n    287             imgs, self.mask_img_, params,\n    288             memory_level=self.memory_level,\n    289             memory=self.memory,\n    290             verbose=self.verbose,\n    291             confounds=confounds,\n--> 292             copy=copy\n        copy = True\n    293         )\n    294 \n    295         return data\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in __call__(self=MemorizedFunc(func=<function filter_and_mask at .../home/share/TmpData/Qinglin/nilearn_cache/joblib), *args=('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}), **kwargs={'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10})\n    537         return MemorizedResult(self.store_backend, self.func, args_id,\n    538                                metadata=metadata, verbose=self._verbose - 1,\n    539                                timestamp=self.timestamp)\n    540 \n    541     def __call__(self, *args, **kwargs):\n--> 542         return self._cached_call(args, kwargs)[0]\n        self._cached_call = <bound method MemorizedFunc._cached_call of Memo...home/share/TmpData/Qinglin/nilearn_cache/joblib)>\n        args = ('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None})\n        kwargs = {'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}\n    543 \n    544     def __getstate__(self):\n    545         \"\"\" We don't store the timestamp when pickling, to avoid the hash\n    546             depending from it.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in _cached_call(self=MemorizedFunc(func=<function filter_and_mask at .../home/share/TmpData/Qinglin/nilearn_cache/joblib), args=('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}), kwargs={'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}, shelving=False)\n    503                           '{}\\n {}'.format(signature, traceback.format_exc()))\n    504 \n    505                 must_call = True\n    506 \n    507         if must_call:\n--> 508             out, metadata = self.call(*args, **kwargs)\n        out = undefined\n        metadata = None\n        self.call = <bound method MemorizedFunc.call of MemorizedFun...home/share/TmpData/Qinglin/nilearn_cache/joblib)>\n        args = ('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None})\n        kwargs = {'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}\n    509             if self.mmap_mode is not None:\n    510                 # Memmap the output at the first call to be consistent with\n    511                 # later calls\n    512                 if self._verbose:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in call(self=MemorizedFunc(func=<function filter_and_mask at .../home/share/TmpData/Qinglin/nilearn_cache/joblib), *args=('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}), **kwargs={'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10})\n    703         \"\"\"\n    704         start_time = time.time()\n    705         func_id, args_id = self._get_output_identifiers(*args, **kwargs)\n    706         if self._verbose > 0:\n    707             print(format_call(self.func, args, kwargs))\n--> 708         output = self.func(*args, **kwargs)\n        output = undefined\n        self.func = <function filter_and_mask>\n        args = ('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None})\n        kwargs = {'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}\n    709         self.store_backend.dump_item(\n    710             [func_id, args_id], output, verbose=self._verbose)\n    711 \n    712         duration = time.time() - start_time\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/input_data/nifti_masker.py in filter_and_mask(imgs='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', mask_img_=<nibabel.nifti1.Nifti1Image object>, parameters={'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}, memory_level=1, memory=Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), verbose=10, confounds=None, copy=True)\n     30 def filter_and_mask(imgs, mask_img_, parameters,\n     31                     memory_level=0, memory=Memory(cachedir=None),\n     32                     verbose=0,\n     33                     confounds=None,\n     34                     copy=True):\n---> 35     imgs = _utils.check_niimg(imgs, atleast_4d=True, ensure_ndim=4)\n        imgs = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n     36 \n     37     # Check whether resampling is truly necessary. If so, crop mask\n     38     # as small as possible in order to speed up the process\n     39 \n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/_utils/niimg_conversions.py in check_niimg(niimg='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ensure_ndim=4, atleast_4d=True, dtype=None, return_iterator=False, wildcards=True)\n    266             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n    267                                      dtype=dtype)\n    268         return concat_niimgs(niimg, ensure_ndim=ensure_ndim, dtype=dtype)\n    269 \n    270     # Otherwise, it should be a filename or a SpatialImage, we load it\n--> 271     niimg = load_niimg(niimg, dtype=dtype)\n        niimg = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n        dtype = None\n    272 \n    273     if ensure_ndim == 3 and len(niimg.shape) == 4 and niimg.shape[3] == 1:\n    274         # \"squeeze\" the image.\n    275         data = _safe_get_data(niimg)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/_utils/niimg.py in load_niimg(niimg=<nibabel.nifti1.Nifti1Image object>, dtype=None)\n    111     elif not isinstance(niimg, nibabel.spatialimages.SpatialImage):\n    112         raise TypeError(\"Data given cannot be loaded because it is\"\n    113                         \" not compatible with nibabel format:\\n\"\n    114                         + short_repr(niimg))\n    115 \n--> 116     dtype = _get_target_dtype(niimg.get_data().dtype, dtype)\n        dtype = None\n        niimg.get_data.dtype = undefined\n    117 \n    118     if dtype is not None:\n    119         niimg = new_img_like(niimg, niimg.get_data().astype(dtype),\n    120                              niimg.affine)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/dataobj_images.py in get_data(self=<nibabel.nifti1.Nifti1Image object>, caching='fill')\n    197         \"\"\"\n    198         if caching not in ('fill', 'unchanged'):\n    199             raise ValueError('caching value should be \"fill\" or \"unchanged\"')\n    200         if self._data_cache is not None:\n    201             return self._data_cache\n--> 202         data = np.asanyarray(self._dataobj)\n        data = undefined\n        self._dataobj = <nibabel.arrayproxy.ArrayProxy object>\n    203         if caching == 'fill':\n    204             self._data_cache = data\n    205         return data\n    206 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.py in asanyarray(a=<nibabel.arrayproxy.ArrayProxy object>, dtype=None, order=None)\n    548     >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)\n    549     >>> np.asanyarray(a) is a\n    550     True\n    551 \n    552     \"\"\"\n--> 553     return array(a, dtype, copy=False, order=order, subok=True)\n        a = <nibabel.arrayproxy.ArrayProxy object>\n        dtype = None\n        order = None\n    554 \n    555 \n    556 def ascontiguousarray(a, dtype=None):\n    557     \"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/arrayproxy.py in __array__(self=<nibabel.arrayproxy.ArrayProxy object>)\n    351                                        mmap=self._mmap)\n    352         return raw_data\n    353 \n    354     def __array__(self):\n    355         # Read array and scale\n--> 356         raw_data = self.get_unscaled()\n        raw_data = undefined\n        self.get_unscaled = <bound method ArrayProxy.get_unscaled of <nibabel.arrayproxy.ArrayProxy object>>\n    357         return apply_read_scaling(raw_data, self._slope, self._inter)\n    358 \n    359     def __getitem__(self, slicer):\n    360         with self._get_fileobj() as fileobj:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/arrayproxy.py in get_unscaled(self=<nibabel.arrayproxy.ArrayProxy object>)\n    346             raw_data = array_from_file(self._shape,\n    347                                        self._dtype,\n    348                                        fileobj,\n    349                                        offset=self._offset,\n    350                                        order=self.order,\n--> 351                                        mmap=self._mmap)\n        self._mmap = True\n    352         return raw_data\n    353 \n    354     def __array__(self):\n    355         # Read array and scale\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/volumeutils.py in array_from_file(shape=(91, 109, 91, 316), in_dtype=dtype('<f4'), infile=<gzip on 0x7f4fcff5f910>, offset=352, order='F', mmap='c')\n    523         return np.array([])\n    524     # Read data from file\n    525     infile.seek(offset)\n    526     if hasattr(infile, 'readinto'):\n    527         data_bytes = bytearray(n_bytes)\n--> 528         n_read = infile.readinto(data_bytes)\n        n_read = undefined\n        infile.readinto = <built-in method readinto of BufferedGzipFile object>\n        data_bytes = bytearray(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00...x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n    529         needs_copy = False\n    530     else:\n    531         data_bytes = infile.read(n_bytes)\n    532         n_read = len(data_bytes)\n\n...........................................................................\n/usr/lib/python2.7/gzip.py in read(self=<gzip on 0x7f4fcff5f910>, size=1140923056)\n    263             except EOFError:\n    264                 size = self.extrasize\n    265         else:               # just get some more of it\n    266             try:\n    267                 while size > self.extrasize:\n--> 268                     self._read(readsize)\n        self._read = <bound method BufferedGzipFile._read of <gzip on 0x7f4fcff5f910>>\n        readsize = 104857600\n    269                     readsize = min(self.max_read_chunk, readsize * 2)\n    270             except EOFError:\n    271                 if size > self.extrasize:\n    272                     size = self.extrasize\n\n...........................................................................\n/usr/lib/python2.7/gzip.py in _read(self=<gzip on 0x7f4fcff5f910>, size=104857600)\n    327             # data, minus 8 because _read_eof() will rewind a further 8 bytes)\n    328             self.fileobj.seek( -len(self.decompress.unused_data)+8, 1)\n    329 \n    330             # Check the CRC and file size, and set the flag so we read\n    331             # a new member on the next call\n--> 332             self._read_eof()\n        self._read_eof = <bound method BufferedGzipFile._read_eof of <gzip on 0x7f4fcff5f910>>\n    333             self._new_member = True\n    334 \n    335     def _add_read_data(self, data):\n    336         self.crc = zlib.crc32(data, self.crc) & 0xffffffffL\n\n...........................................................................\n/usr/lib/python2.7/gzip.py in _read_eof(self=<gzip on 0x7f4fcff5f910>)\n    349         self.fileobj.seek(-8, 1)\n    350         crc32 = read32(self.fileobj)\n    351         isize = read32(self.fileobj)  # may exceed 2GB\n    352         if crc32 != self.crc:\n    353             raise IOError(\"CRC check failed %s != %s\" % (hex(crc32),\n--> 354                                                          hex(self.crc)))\n        self.crc = 3302384720L\n    355         elif isize != (self.size & 0xffffffffL):\n    356             raise IOError, \"Incorrect length of data produced\"\n    357 \n    358         # Gzip files can be padded with zeroes and still have archives.\n\nIOError: CRC check failed 0x577cb4bd != 0xc4d66450L\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibIOError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63ea1ef337ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/share/TmpData/Qinglin/nilearn_cache\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 threshold=3., verbose=10, random_state=0,n_jobs=8)\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcanica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.pyc\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, imgs, y, confounds, reduction_ratio)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_level\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             n_jobs=self.n_jobs)\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.pyc\u001b[0m in \u001b[0;36mmask_and_reduce\u001b[0;34m(masker, imgs, confounds, reduction_ratio, n_components, random_state, memory_level, memory, n_jobs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         ) for img, confound in zip(imgs, confounds))\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     subject_n_samples = [subject_data.shape[0]\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    926\u001b[0m                     this_report = format_outer_frames(context=10,\n\u001b[1;32m    927\u001b[0m                                                       stack_start=1)\n\u001b[0;32m--> 928\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibIOError\u001b[0m: JoblibIOError\n___________________________________________________________________________\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f54e43b48b0, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f54e43b48b0, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    494         if self.poller is not None:\n    495             self.poller.start()\n    496         self.kernel.start()\n    497         self.io_loop = ioloop.IOLoop.current()\n    498         try:\n--> 499             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    500         except KeyboardInterrupt:\n    501             pass\n    502 \n    503 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n   1068                 self._events.update(event_pairs)\n   1069                 while self._events:\n   1070                     fd, events = self._events.popitem()\n   1071                     try:\n   1072                         fd_obj, handler_func = self._handlers[fd]\n-> 1073                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n   1074                     except (OSError, IOError) as e:\n   1075                         if errno_from_exception(e) == errno.EPIPE:\n   1076                             # Happens when the client closes the connection\n   1077                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 10, 20, 14, 38, 46, 279769, tzinfo=tzutc()), u'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', u'msg_type': u'execute_request', u'session': u'e59763e82f0e40db8130b18fb5b3ce95', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['e59763e82f0e40db8130b18fb5b3ce95']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 10, 20, 14, 38, 46, 279769, tzinfo=tzutc()), u'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', u'msg_type': u'execute_request', u'session': u'e59763e82f0e40db8130b18fb5b3ce95', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['e59763e82f0e40db8130b18fb5b3ce95'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 10, 20, 14, 38, 46, 279769, tzinfo=tzutc()), u'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', u'msg_type': u'execute_request', u'session': u'e59763e82f0e40db8130b18fb5b3ce95', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'7d665110a1d64dbcb20f6eb14f826469', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...are/TmpData/Qinglin/nilearn_cache\\')\\n        \\n', store_history=True, silent=False, shell_futures=True)\n   2709                 self.displayhook.exec_result = result\n   2710 \n   2711                 # Execute the user code\n   2712                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2713                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2714                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2715                 \n   2716                 self.last_execution_succeeded = not has_raised\n   2717 \n   2718                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Import object>, <_ast.Assign object>, <_ast.If object>, <_ast.ImportFrom object>, <_ast.For object>], cell_name='<ipython-input-1-63ea1ef337ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f54dc257ed0, executi..._before_exec=None error_in_exec=None result=None>)\n   2813 \n   2814         try:\n   2815             for i, node in enumerate(to_run_exec):\n   2816                 mod = ast.Module([node])\n   2817                 code = compiler(mod, cell_name, \"exec\")\n-> 2818                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f54dc2561b0, file \"<ipython-input-1-63ea1ef337ba>\", line 12>\n        result = <ExecutionResult object at 7f54dc257ed0, executi..._before_exec=None error_in_exec=None result=None>\n   2819                     return True\n   2820 \n   2821             for i, node in enumerate(to_run_interactive):\n   2822                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f54dc2561b0, file \"<ipython-input-1-63ea1ef337ba>\", line 12>, result=<ExecutionResult object at 7f54dc257ed0, executi..._before_exec=None error_in_exec=None result=None>)\n   2873         outflag = 1  # happens in more places, so it's easier as default\n   2874         try:\n   2875             try:\n   2876                 self.hooks.pre_run_code_hook()\n   2877                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2878                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f54dc2561b0, file \"<ipython-input-1-63ea1ef337ba>\", line 12>\n        self.user_global_ns = {'CanICA': <class 'nilearn.decomposition.canica.CanICA'>, 'In': ['', u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...share/TmpData/Qinglin/nilearn_cache\\')\\n        '], 'Out': {}, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__name__': '__main__', ...}\n        self.user_ns = {'CanICA': <class 'nilearn.decomposition.canica.CanICA'>, 'In': ['', u'task=[\\'EMOTION\\',\\'RELATIONAL\\',\\'SOCIAL\\',\\'...share/TmpData/Qinglin/nilearn_cache\\')\\n        '], 'Out': {}, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Automatically created module for IPython interactive environment', '__name__': '__main__', ...}\n   2879             finally:\n   2880                 # Reset our crash handler in place\n   2881                 sys.excepthook = old_excepthook\n   2882         except SystemExit as e:\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/experiments/<ipython-input-1-63ea1ef337ba> in <module>()\n     19             func_filenames.append(file)   \n     20     func_filenames=func_filenames[:100]\n     21     canica = CanICA(n_components=40, mask=mask_img, smoothing_fwhm=6.,\n     22                 memory=\"/home/share/TmpData/Qinglin/nilearn_cache\", memory_level=2,\n     23                 threshold=3., verbose=10, random_state=0,n_jobs=8)\n---> 24     data=canica.prepare_data(func_filenames, reduction_ratio=0.2)\n     25     print(data.shape)\n     26 \n     27     import numpy as np\n     28     np.save('/home/share/TmpData/Qinglin/HCP_Group/'+t+'100_0.2.npy', data)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py in prepare_data(self=CanICA(detrend=True, do_cca=True, high_pass=None...    target_shape=None, threshold=3.0, verbose=10), imgs=['/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/183337/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/181636/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/751348/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/102816/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/179548/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/268749/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/686969/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/170631/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/144125/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/341834/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/134425/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/130417/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/173839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/156233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/122620/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/433839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/129028/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/139233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/178647/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ...], y=None, confounds=None, reduction_ratio=0.2)\n    407             reduction_ratio=reduction_ratio,\n    408             n_components=self.n_components,\n    409             random_state=self.random_state,\n    410             memory=self.memory,\n    411             memory_level=max(0, self.memory_level + 1),\n--> 412             n_jobs=self.n_jobs)\n        self.n_jobs = 8\n    413         return data\n    414 \n    415     def fit(self, imgs, y=None, confounds=None):\n    416         data= self.prepare_data(imgs, y, confounds)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py in mask_and_reduce(masker=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), imgs=['/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/183337/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/181636/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/751348/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/102816/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/179548/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/268749/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/686969/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/170631/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/144125/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/341834/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/134425/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/130417/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/173839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/156233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/122620/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/433839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/129028/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/139233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/178647/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ...], confounds=repeat(None), reduction_ratio=0.2, n_components=40, random_state=0, memory_level=3, memory='/home/share/TmpData/Qinglin/nilearn_cache', n_jobs=8)\n    173             reduction_ratio=reduction_ratio,\n    174             n_samples=n_samples,\n    175             memory=memory,\n    176             memory_level=memory_level,\n    177             random_state=random_state\n--> 178         ) for img, confound in zip(imgs, confounds))\n        imgs = ['/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/183337/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/181636/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/751348/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/102816/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/179548/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/268749/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/686969/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/170631/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/144125/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/341834/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/134425/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/130417/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/173839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/156233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/122620/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/433839/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/129028/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/139233/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Motor/178647/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ...]\n        confounds = repeat(None)\n    179 \n    180     subject_n_samples = [subject_data.shape[0]\n    181                          for subject_data in data_list]\n    182 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    991                 # No need to wait for async callbacks to trigger to\n    992                 # consumption.\n    993                 self._iterating = False\n    994 \n    995             with self._backend.retrieval_context():\n--> 996                 self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    997             # Make sure that we get a last message telling us we are done\n    998             elapsed_time = time.time() - self._start_time\n    999             self._print('Done %3i out of %3i | elapsed: %s finished',\n   1000                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nJoblib worker traceback:\n---------------------------------------------------------------------------\nIOError                                            Sat Oct 20 12:18:16 2018\nPID: 20361                                   Python 2.7.12: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    256         self._pickle_cache = pickle_cache if pickle_cache is not None else {}\n    257 \n    258     def __call__(self):\n    259         with parallel_backend(self._backend):\n    260             return [func(*args, **kwargs)\n--> 261                     for func, args, kwargs in self.items]\n        func = <function _mask_and_reduce_single>\n        args = [MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', None]\n        kwargs = {'memory': '/home/share/TmpData/Qinglin/nilearn_cache', 'memory_level': 3, 'n_samples': None, 'random_state': 0, 'reduction_ratio': 0.2}\n        self.items = [(<function _mask_and_reduce_single>, [MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', None], {'memory': '/home/share/TmpData/Qinglin/nilearn_cache', 'memory_level': 3, 'n_samples': None, 'random_state': 0, 'reduction_ratio': 0.2})]\n    262 \n    263     def __len__(self):\n    264         return self._size\n    265 \n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py in _mask_and_reduce_single(masker=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), img='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', confound=None, reduction_ratio=0.2, n_samples=None, memory='/home/share/TmpData/Qinglin/nilearn_cache', memory_level=3, random_state=0)\n    203                             n_samples=None,\n    204                             memory=None,\n    205                             memory_level=0,\n    206                             random_state=None):\n    207     \"\"\"Utility function for multiprocessing from MaskReducer\"\"\"\n--> 208     this_data = masker.transform(img, confound)\n        this_data = undefined\n        masker.transform = <bound method MultiNiftiMasker.transform of Mult...rget_affine=None, target_shape=None, verbose=10)>\n        img = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n        confound = None\n    209     # Now get rid of the img as fast as possible, to free a\n    210     # reference count on it, and possibly free the corresponding\n    211     # data\n    212     del img\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/input_data/multi_nifti_masker.py in transform(self=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), imgs='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', confounds=None)\n    303             preprocessed images\n    304         \"\"\"\n    305         self._check_fitted()\n    306         if not hasattr(imgs, '__iter__') \\\n    307                 or isinstance(imgs, _basestring):\n--> 308             return self.transform_single_imgs(imgs)\n        self.transform_single_imgs = <bound method MultiNiftiMasker.transform_single_...rget_affine=None, target_shape=None, verbose=10)>\n        imgs = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n    309         return self.transform_imgs(imgs, confounds, n_jobs=self.n_jobs)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/input_data/nifti_masker.py in transform_single_imgs(self=MultiNiftiMasker(detrend=True, high_pass=None, l...arget_affine=None, target_shape=None, verbose=10), imgs='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', confounds=None, copy=True)\n    287             imgs, self.mask_img_, params,\n    288             memory_level=self.memory_level,\n    289             memory=self.memory,\n    290             verbose=self.verbose,\n    291             confounds=confounds,\n--> 292             copy=copy\n        copy = True\n    293         )\n    294 \n    295         return data\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in __call__(self=MemorizedFunc(func=<function filter_and_mask at .../home/share/TmpData/Qinglin/nilearn_cache/joblib), *args=('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}), **kwargs={'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10})\n    537         return MemorizedResult(self.store_backend, self.func, args_id,\n    538                                metadata=metadata, verbose=self._verbose - 1,\n    539                                timestamp=self.timestamp)\n    540 \n    541     def __call__(self, *args, **kwargs):\n--> 542         return self._cached_call(args, kwargs)[0]\n        self._cached_call = <bound method MemorizedFunc._cached_call of Memo...home/share/TmpData/Qinglin/nilearn_cache/joblib)>\n        args = ('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None})\n        kwargs = {'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}\n    543 \n    544     def __getstate__(self):\n    545         \"\"\" We don't store the timestamp when pickling, to avoid the hash\n    546             depending from it.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in _cached_call(self=MemorizedFunc(func=<function filter_and_mask at .../home/share/TmpData/Qinglin/nilearn_cache/joblib), args=('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}), kwargs={'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}, shelving=False)\n    503                           '{}\\n {}'.format(signature, traceback.format_exc()))\n    504 \n    505                 must_call = True\n    506 \n    507         if must_call:\n--> 508             out, metadata = self.call(*args, **kwargs)\n        out = undefined\n        metadata = None\n        self.call = <bound method MemorizedFunc.call of MemorizedFun...home/share/TmpData/Qinglin/nilearn_cache/joblib)>\n        args = ('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None})\n        kwargs = {'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}\n    509             if self.mmap_mode is not None:\n    510                 # Memmap the output at the first call to be consistent with\n    511                 # later calls\n    512                 if self._verbose:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in call(self=MemorizedFunc(func=<function filter_and_mask at .../home/share/TmpData/Qinglin/nilearn_cache/joblib), *args=('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}), **kwargs={'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10})\n    703         \"\"\"\n    704         start_time = time.time()\n    705         func_id, args_id = self._get_output_identifiers(*args, **kwargs)\n    706         if self._verbose > 0:\n    707             print(format_call(self.func, args, kwargs))\n--> 708         output = self.func(*args, **kwargs)\n        output = undefined\n        self.func = <function filter_and_mask>\n        args = ('/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', <nibabel.nifti1.Nifti1Image object>, {'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None})\n        kwargs = {'confounds': None, 'copy': True, 'memory': Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), 'memory_level': 1, 'verbose': 10}\n    709         self.store_backend.dump_item(\n    710             [func_id, args_id], output, verbose=self._verbose)\n    711 \n    712         duration = time.time() - start_time\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/input_data/nifti_masker.py in filter_and_mask(imgs='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', mask_img_=<nibabel.nifti1.Nifti1Image object>, parameters={'detrend': True, 'high_pass': None, 'low_pass': None, 'smoothing_fwhm': 6.0, 'standardize': True, 't_r': None, 'target_affine': None, 'target_shape': None}, memory_level=1, memory=Memory(location=/home/share/TmpData/Qinglin/nilearn_cache/joblib), verbose=10, confounds=None, copy=True)\n     30 def filter_and_mask(imgs, mask_img_, parameters,\n     31                     memory_level=0, memory=Memory(cachedir=None),\n     32                     verbose=0,\n     33                     confounds=None,\n     34                     copy=True):\n---> 35     imgs = _utils.check_niimg(imgs, atleast_4d=True, ensure_ndim=4)\n        imgs = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n     36 \n     37     # Check whether resampling is truly necessary. If so, crop mask\n     38     # as small as possible in order to speed up the process\n     39 \n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/_utils/niimg_conversions.py in check_niimg(niimg='/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz', ensure_ndim=4, atleast_4d=True, dtype=None, return_iterator=False, wildcards=True)\n    266             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n    267                                      dtype=dtype)\n    268         return concat_niimgs(niimg, ensure_ndim=ensure_ndim, dtype=dtype)\n    269 \n    270     # Otherwise, it should be a filename or a SpatialImage, we load it\n--> 271     niimg = load_niimg(niimg, dtype=dtype)\n        niimg = '/home/share/TmpData/Qinglin/HCP_Motor/149842/MNI...esults/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz'\n        dtype = None\n    272 \n    273     if ensure_ndim == 3 and len(niimg.shape) == 4 and niimg.shape[3] == 1:\n    274         # \"squeeze\" the image.\n    275         data = _safe_get_data(niimg)\n\n...........................................................................\n/home/uga_qinglin/Documents/nilearn-deep/nilearn/_utils/niimg.py in load_niimg(niimg=<nibabel.nifti1.Nifti1Image object>, dtype=None)\n    111     elif not isinstance(niimg, nibabel.spatialimages.SpatialImage):\n    112         raise TypeError(\"Data given cannot be loaded because it is\"\n    113                         \" not compatible with nibabel format:\\n\"\n    114                         + short_repr(niimg))\n    115 \n--> 116     dtype = _get_target_dtype(niimg.get_data().dtype, dtype)\n        dtype = None\n        niimg.get_data.dtype = undefined\n    117 \n    118     if dtype is not None:\n    119         niimg = new_img_like(niimg, niimg.get_data().astype(dtype),\n    120                              niimg.affine)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/dataobj_images.py in get_data(self=<nibabel.nifti1.Nifti1Image object>, caching='fill')\n    197         \"\"\"\n    198         if caching not in ('fill', 'unchanged'):\n    199             raise ValueError('caching value should be \"fill\" or \"unchanged\"')\n    200         if self._data_cache is not None:\n    201             return self._data_cache\n--> 202         data = np.asanyarray(self._dataobj)\n        data = undefined\n        self._dataobj = <nibabel.arrayproxy.ArrayProxy object>\n    203         if caching == 'fill':\n    204             self._data_cache = data\n    205         return data\n    206 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.py in asanyarray(a=<nibabel.arrayproxy.ArrayProxy object>, dtype=None, order=None)\n    548     >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)\n    549     >>> np.asanyarray(a) is a\n    550     True\n    551 \n    552     \"\"\"\n--> 553     return array(a, dtype, copy=False, order=order, subok=True)\n        a = <nibabel.arrayproxy.ArrayProxy object>\n        dtype = None\n        order = None\n    554 \n    555 \n    556 def ascontiguousarray(a, dtype=None):\n    557     \"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/arrayproxy.py in __array__(self=<nibabel.arrayproxy.ArrayProxy object>)\n    351                                        mmap=self._mmap)\n    352         return raw_data\n    353 \n    354     def __array__(self):\n    355         # Read array and scale\n--> 356         raw_data = self.get_unscaled()\n        raw_data = undefined\n        self.get_unscaled = <bound method ArrayProxy.get_unscaled of <nibabel.arrayproxy.ArrayProxy object>>\n    357         return apply_read_scaling(raw_data, self._slope, self._inter)\n    358 \n    359     def __getitem__(self, slicer):\n    360         with self._get_fileobj() as fileobj:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/arrayproxy.py in get_unscaled(self=<nibabel.arrayproxy.ArrayProxy object>)\n    346             raw_data = array_from_file(self._shape,\n    347                                        self._dtype,\n    348                                        fileobj,\n    349                                        offset=self._offset,\n    350                                        order=self.order,\n--> 351                                        mmap=self._mmap)\n        self._mmap = True\n    352         return raw_data\n    353 \n    354     def __array__(self):\n    355         # Read array and scale\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/nibabel/volumeutils.py in array_from_file(shape=(91, 109, 91, 316), in_dtype=dtype('<f4'), infile=<gzip on 0x7f4fcff5f910>, offset=352, order='F', mmap='c')\n    523         return np.array([])\n    524     # Read data from file\n    525     infile.seek(offset)\n    526     if hasattr(infile, 'readinto'):\n    527         data_bytes = bytearray(n_bytes)\n--> 528         n_read = infile.readinto(data_bytes)\n        n_read = undefined\n        infile.readinto = <built-in method readinto of BufferedGzipFile object>\n        data_bytes = bytearray(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00...x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n    529         needs_copy = False\n    530     else:\n    531         data_bytes = infile.read(n_bytes)\n    532         n_read = len(data_bytes)\n\n...........................................................................\n/usr/lib/python2.7/gzip.py in read(self=<gzip on 0x7f4fcff5f910>, size=1140923056)\n    263             except EOFError:\n    264                 size = self.extrasize\n    265         else:               # just get some more of it\n    266             try:\n    267                 while size > self.extrasize:\n--> 268                     self._read(readsize)\n        self._read = <bound method BufferedGzipFile._read of <gzip on 0x7f4fcff5f910>>\n        readsize = 104857600\n    269                     readsize = min(self.max_read_chunk, readsize * 2)\n    270             except EOFError:\n    271                 if size > self.extrasize:\n    272                     size = self.extrasize\n\n...........................................................................\n/usr/lib/python2.7/gzip.py in _read(self=<gzip on 0x7f4fcff5f910>, size=104857600)\n    327             # data, minus 8 because _read_eof() will rewind a further 8 bytes)\n    328             self.fileobj.seek( -len(self.decompress.unused_data)+8, 1)\n    329 \n    330             # Check the CRC and file size, and set the flag so we read\n    331             # a new member on the next call\n--> 332             self._read_eof()\n        self._read_eof = <bound method BufferedGzipFile._read_eof of <gzip on 0x7f4fcff5f910>>\n    333             self._new_member = True\n    334 \n    335     def _add_read_data(self, data):\n    336         self.crc = zlib.crc32(data, self.crc) & 0xffffffffL\n\n...........................................................................\n/usr/lib/python2.7/gzip.py in _read_eof(self=<gzip on 0x7f4fcff5f910>)\n    349         self.fileobj.seek(-8, 1)\n    350         crc32 = read32(self.fileobj)\n    351         isize = read32(self.fileobj)  # may exceed 2GB\n    352         if crc32 != self.crc:\n    353             raise IOError(\"CRC check failed %s != %s\" % (hex(crc32),\n--> 354                                                          hex(self.crc)))\n        self.crc = 3302384720L\n    355         elif isize != (self.size & 0xffffffffL):\n    356             raise IOError, \"Incorrect length of data produced\"\n    357 \n    358         # Gzip files can be padded with zeroes and still have archives.\n\nIOError: CRC check failed 0x577cb4bd != 0xc4d66450L\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "task=['MOTOR','EMOTION','RELATIONAL','SOCIAL','WM','GAMBLING']\n",
    "\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "import os\n",
    "cache='/home/share/TmpData/Qinglin/nilearn_cache'\n",
    "if not os.path.exists(cache):\n",
    "    os.makedirs(cache)\n",
    "    \n",
    "from nilearn.decomposition import CanICA\n",
    "for t in task:\n",
    "    print t\n",
    "    func_filenames=[]\n",
    "    for x in os.listdir('/home/share/TmpData/Qinglin/HCP_Motor'):\n",
    "        file='/home/share/TmpData/Qinglin/HCP_Motor/'+str(x)+'/MNINonLinear/Results/tfMRI_'+str(t)+'_LR/tfMRI_'+str(t)+'_LR.nii.gz'\n",
    "        #print file\n",
    "        if os.path.isfile(file):\n",
    "            func_filenames.append(file)   \n",
    "    func_filenames=func_filenames[:100]\n",
    "    canica = CanICA(n_components=40, mask=mask_img, smoothing_fwhm=6.,\n",
    "                memory=\"/home/share/TmpData/Qinglin/nilearn_cache\", memory_level=2,\n",
    "                threshold=3., verbose=10, random_state=0,n_jobs=8)\n",
    "    data=canica.prepare_data(func_filenames, reduction_ratio=0.2)\n",
    "    print(data.shape)\n",
    "\n",
    "    import numpy as np\n",
    "    np.save('/home/share/TmpData/Qinglin/HCP_Group/'+t+'100_0.2.npy', data)\n",
    "    del canica\n",
    "    import shutil\n",
    "    shutil.rmtree('/home/share/TmpData/Qinglin/nilearn_cache')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize we plot the outline of all components on one figure\n",
    "-----------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the map for each ICA component separately\n",
    "-----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGUAGE\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/183337/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/181636/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/751348/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/102816/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/179548/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/268749/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/686969/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/170631/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/144125/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/341834/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/134425/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/130417/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/173839/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/156233/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/122620/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/433839/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/129028/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/139233/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/178647/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/187547/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/187547/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/169949/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/169949/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/346945/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/346945/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/547046/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/547046/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 0.90s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/366042/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/366042/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.02s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/429040/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/429040/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.75s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/749058/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/749058/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/140824/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/140824/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/561242/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/561242/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/211114/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/211114/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/146533/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/146533/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/112920/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/112920/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 0.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/601127/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/601127/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/194746/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/194746/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/160123/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/160123/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/816653/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/816653/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/499566/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/499566/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/852455/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/852455/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/572045/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/572045/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/214423/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/214423/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/307127/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/307127/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/103818/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/103818/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/161731/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/161731/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/380036/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/380036/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/200109/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/200109/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/181232/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/181232/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/180432/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/180432/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 0.81s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/604537/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/604537/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/289555/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/289555/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/837964/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/837964/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/138837/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/138837/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/211922/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/211922/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/121618/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/121618/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/170934/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/170934/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/111009/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/111009/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/101410/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/101410/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/221319/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/221319/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/110007/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/110007/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/201818/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/201818/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/161327/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/161327/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/663755/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/663755/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/562446/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/562446/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/579867/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/579867/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/236130/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/236130/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/124624/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/124624/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/123925/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/123925/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/693764/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/693764/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.99s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/992774/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/992774/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/129129/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/129129/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/206222/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/206222/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/224022/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/224022/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/214221/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/214221/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/200210/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/200210/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/899885/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/899885/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/255639/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/255639/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/118528/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/118528/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/555651/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/555651/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/673455/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/673455/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/873968/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/873968/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/178142/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/178142/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/121416/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/121416/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/180129/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/180129/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/146331/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/146331/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/172534/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/172534/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/979984/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/979984/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 0.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/150524/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/150524/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/110613/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/110613/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/683256/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/683256/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.42s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Motor/322224/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/322224/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/214524/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/214524/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/303119/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/303119/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/645450/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/645450/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/552544/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/552544/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/157336/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/157336/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/158136/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/158136/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/114823/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/114823/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/217429/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/217429/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/164939/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/164939/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/947668/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/947668/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/336841/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/336841/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/179346/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/179346/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/803240/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/803240/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Motor/141119/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Motor/141119/MNINonLinear/Results/tfMRI_LANGUAGE_LR/tfMRI_LANGUAGE_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "(6528, 228453)\n"
     ]
    }
   ],
   "source": [
    "task=['LANGUAGE']\n",
    "\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "import os\n",
    "cache='/home/share/TmpData/Qinglin/nilearn_cache'\n",
    "if not os.path.exists(cache):\n",
    "    os.makedirs(cache)\n",
    "    \n",
    "from nilearn.decomposition import CanICA\n",
    "for t in task:\n",
    "    print t\n",
    "    func_filenames=[]\n",
    "    for x in os.listdir('/home/share/TmpData/Qinglin/HCP_Motor'):\n",
    "        file='/home/share/TmpData/Qinglin/HCP_Motor/'+str(x)+'/MNINonLinear/Results/tfMRI_'+str(t)+'_LR/tfMRI_'+str(t)+'_LR.nii.gz'\n",
    "        #print file\n",
    "        if os.path.isfile(file):\n",
    "            func_filenames.append(file)   \n",
    "    func_filenames=func_filenames[:102]\n",
    "    canica = CanICA(n_components=40, mask=mask_img, smoothing_fwhm=6.,\n",
    "                memory=\"/home/share/TmpData/Qinglin/nilearn_cache\", memory_level=2,\n",
    "                threshold=3., verbose=10, random_state=0,n_jobs=1)\n",
    "    data=canica.prepare_data(func_filenames, reduction_ratio=0.2)\n",
    "    print(data.shape)\n",
    "\n",
    "    import numpy as np\n",
    "    np.save('/home/share/TmpData/Qinglin/HCP_Group/'+t+'100_0.2.npy', data)\n",
    "    del canica\n",
    "    import shutil\n",
    "    shutil.rmtree('/home/share/TmpData/Qinglin/nilearn_cache')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/share/TmpData/Qinglin/HCP_Resting/751348/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/102816/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/156233/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/122620/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/433839/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/129028/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/139233/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/187547/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/547046/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/366042/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/140824/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/561242/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/211114/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/601127/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/160123/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/816653/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/499566/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/214423/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/307127/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/103818/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/161731/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/112819/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/380036/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/200109/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/181232/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/180432/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/289555/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/837964/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/211922/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/121618/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/170934/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/101410/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/221319/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/201818/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/161327/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/562446/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/145531/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/123925/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/992774/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/224022/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/214221/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/899885/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/255639/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/118528/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/673455/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/178142/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/180129/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/146331/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/172534/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/979984/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/150524/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/683256/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/303119/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/552544/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/157336/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/158136/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/217429/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/164939/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/179346/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/120212/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/199453/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/145834/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/965367/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/620434/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/144226/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/549757/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/521331/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/782561/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/122317/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/371843/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/116524/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/217126/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/124220/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/177746/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/901038/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/146432/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/784565/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/138534/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/352738/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/857263/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/185442/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/290136/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/690152/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/729254/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/685058/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/211316/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/531536/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/748662/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/715647/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/134324/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/150423/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/559053/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/994273/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/205119/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/365343/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/473952/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/833148/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/149337/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/175035/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz', '/home/share/TmpData/Qinglin/HCP_Resting/194847/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz']\n",
      "[MultiNiftiMasker.fit] Loading data from None\n",
      "[MultiNiftiMasker.transform] Resampling mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CanICA] Loading data\n",
      "/home/share/TmpData/Qinglin/HCP_Resting/751348/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Resting/751348/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.53s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Resting/102816/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Resting/102816/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Resting/156233/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Resting/156233/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "/home/share/TmpData/Qinglin/HCP_Resting/122620/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Resting/122620/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Resting/433839/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Resting/433839/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Resting/129028/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Resting/129028/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/nilearn-deep/nilearn/decomposition/base.py:227: UserWarning: Persisting input arguments took 1.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  random_state=random_state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_Resting/139233/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/share/TmpData/Qinglin/HCP_Resting/139233/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "import os\n",
    "cache='/home/share/TmpData/Qinglin/nilearn_cache'\n",
    "if not os.path.exists(cache):\n",
    "    os.makedirs(cache)\n",
    "    \n",
    "from nilearn.decomposition import CanICA\n",
    "\n",
    "\n",
    "func_filenames=[]\n",
    "for x in os.listdir('/home/share/TmpData/Qinglin/HCP_Resting'):    \n",
    "    file='/home/share/TmpData/Qinglin/HCP_Resting/'+str(x)+'/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.nii.gz'\n",
    "   # print file\n",
    "    if os.path.isfile(file):\n",
    "        func_filenames.append(file)   \n",
    "func_filenames=func_filenames[:100]\n",
    "print func_filenames\n",
    "canica = CanICA(n_components=40, mask=mask_img, smoothing_fwhm=6.,\n",
    "            memory=\"/home/share/TmpData/Qinglin/nilearn_cache\", memory_level=2,\n",
    "            threshold=3., verbose=10, random_state=0,n_jobs=1)\n",
    "data=canica.prepare_data(func_filenames, reduction_ratio=0.05)\n",
    "print(data.shape)\n",
    "\n",
    "import numpy as np\n",
    "np.save('/home/share/TmpData/Qinglin/HCP_Group/resting_100_0.2.npy', data)\n",
    "del canica\n",
    "import shutil\n",
    "shutil.rmtree('/home/share/TmpData/Qinglin/nilearn_cache')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print func_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
