{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=np.load('/home/share/TmpData/Qinglin/HCP_Group/MOTOR100_0.2.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 228453)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decomposition.rbm import RBM\n",
    "\n",
    "rbm1=RBM(data.shape[1],100,epochs=3)\n",
    "rbm1.train(data)\n",
    "h1=rbm1.predict(data)\n",
    "\n",
    "rbm2=RBM(100,100,epochs=3)\n",
    "rbm2.train(h1)\n",
    "h2=rbm2.predict(h1)\n",
    "\n",
    "rbm3=RBM(100,100,epochs=3)\n",
    "rbm3.train(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 plot layer1\n",
    "-----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nilearn.decomposition.rbm import getW\n",
    "\n",
    "components_img=rbm1.getW()\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask_img, standardize=True)\n",
    "masker.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decomposition import CanICA\n",
    "\n",
    "canica = CanICA(n_components=20, smoothing_fwhm=6.,\n",
    "                memory=\"nilearn_cache\", memory_level=2,\n",
    "                threshold=3., verbose=10, random_state=0)\n",
    "import numpy as np\n",
    "components_img=np.transpose(components_img)\n",
    "#components_img=canica.thresholding(components_img)\n",
    "components_img = masker.inverse_transform(components_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for i, cur_img in enumerate(iter_img(components_img)):\n",
    "    plot_stat_map(cur_img, display_mode=\"z\", title=\"IC %d\" % i,\n",
    "                  cut_coords=1, colorbar=False)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Region Extractor algorithm from regions module\n",
    "# threshold=0.5 indicates that we keep nominal of amount nonzero voxels across all\n",
    "# maps, less the threshold means that more intense non-voxels will be survived.\n",
    "from nilearn.regions import RegionExtractor\n",
    "\n",
    "extractor = RegionExtractor(components_img, threshold=0.5,\n",
    "                            thresholding_strategy='ratio_n_voxels',\n",
    "                            extractor='local_regions',\n",
    "                            standardize=True, min_region_size=5000)\n",
    "# Just call fit() to process for regions extraction\n",
    "extractor.fit()\n",
    "# Extracted regions are stored in regions_img_\n",
    "regions_extracted_img = extractor.regions_img_\n",
    "# Each region index is stored in index_\n",
    "regions_index = extractor.index_\n",
    "# Total number of regions extracted\n",
    "n_regions_extracted = regions_extracted_img.shape[-1]\n",
    "\n",
    "from nilearn.plotting import plot_prob_atlas\n",
    "# Visualization of region extraction results\n",
    "title = ('%d regions are extracted from %s components.'\n",
    "         '\\nEach separate color of region indicates extracted region'\n",
    "         % (n_regions_extracted, 'all'))\n",
    "plot_prob_atlas(regions_extracted_img, view_type='filled_contours',\n",
    "                         title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 plot layer2\n",
    "-----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nilearn.decomposition.rbm import getW\n",
    "\n",
    "components_img=np.matmul(rbm1.getW(),rbm2.getW())\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask_img, standardize=True)\n",
    "masker.fit()\n",
    "\n",
    "\n",
    "from nilearn.decomposition import CanICA\n",
    "\n",
    "canica = CanICA(n_components=20, smoothing_fwhm=6.,\n",
    "                memory=\"nilearn_cache\", memory_level=2,\n",
    "                threshold=3., verbose=10, random_state=0)\n",
    "import numpy as np\n",
    "components_img=np.transpose(components_img)\n",
    "#components_img=canica.thresholding(components_img)\n",
    "\n",
    "import scipy\n",
    "scipy.stats.mstats.zscore(components_img,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_img[np.absolute(components_img) < 1.7] = 0\n",
    "components_img = masker.inverse_transform(components_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for i, cur_img in enumerate(iter_img(components_img)):\n",
    "    plot_stat_map(cur_img, display_mode=\"z\", title=\"IC %d\" % i,\n",
    "                  cut_coords=1, colorbar=False)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Region Extractor algorithm from regions module\n",
    "# threshold=0.5 indicates that we keep nominal of amount nonzero voxels across all\n",
    "# maps, less the threshold means that more intense non-voxels will be survived.\n",
    "from nilearn.regions import RegionExtractor\n",
    "\n",
    "extractor = RegionExtractor(components_img, threshold=0.5,\n",
    "                            thresholding_strategy='ratio_n_voxels',\n",
    "                            extractor='local_regions',\n",
    "                            standardize=True, min_region_size=1000)\n",
    "# Just call fit() to process for regions extraction\n",
    "extractor.fit()\n",
    "# Extracted regions are stored in regions_img_\n",
    "regions_extracted_img = extractor.regions_img_\n",
    "# Each region index is stored in index_\n",
    "regions_index = extractor.index_\n",
    "# Total number of regions extracted\n",
    "n_regions_extracted = regions_extracted_img.shape[-1]\n",
    "\n",
    "from nilearn.plotting import plot_prob_atlas\n",
    "# Visualization of region extraction results\n",
    "title = ('%d regions are extracted from %s components.'\n",
    "         '\\nEach separate color of region indicates extracted region'\n",
    "         % (n_regions_extracted, 'all'))\n",
    "plot_prob_atlas(regions_extracted_img, view_type='filled_contours',\n",
    "                         title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 plot layer3\n",
    "-----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nilearn.decomposition.rbm import getW\n",
    "\n",
    "components_img=np.matmul(rbm1.getW(),rbm2.getW())\n",
    "components_img=np.matmul(components_img,rbm3.getW())\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask_img, standardize=True)\n",
    "masker.fit()\n",
    "\n",
    "\n",
    "from nilearn.decomposition import CanICA\n",
    "\n",
    "canica = CanICA(n_components=20, smoothing_fwhm=6.,\n",
    "                memory=\"nilearn_cache\", memory_level=2,\n",
    "                threshold=3., verbose=10, random_state=0)\n",
    "import numpy as np\n",
    "components_img=np.transpose(components_img)\n",
    "#components_img=canica.thresholding(components_img)\n",
    "components_img = masker.inverse_transform(components_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for i, cur_img in enumerate(iter_img(components_img)):\n",
    "    plot_stat_map(cur_img, display_mode=\"z\", title=\"IC %d\" % i,\n",
    "                  cut_coords=1, colorbar=False)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Region Extractor algorithm from regions module\n",
    "# threshold=0.5 indicates that we keep nominal of amount nonzero voxels across all\n",
    "# maps, less the threshold means that more intense non-voxels will be survived.\n",
    "from nilearn.regions import RegionExtractor\n",
    "\n",
    "extractor = RegionExtractor(components_img, threshold=0.5,\n",
    "                            thresholding_strategy='ratio_n_voxels',\n",
    "                            extractor='local_regions',\n",
    "                            standardize=True, min_region_size=5000)\n",
    "# Just call fit() to process for regions extraction\n",
    "extractor.fit()\n",
    "# Extracted regions are stored in regions_img_\n",
    "regions_extracted_img = extractor.regions_img_\n",
    "# Each region index is stored in index_\n",
    "regions_index = extractor.index_\n",
    "# Total number of regions extracted\n",
    "n_regions_extracted = regions_extracted_img.shape[-1]\n",
    "\n",
    "from nilearn.plotting import plot_prob_atlas\n",
    "# Visualization of region extraction results\n",
    "title = ('%d regions are extracted from %s components.'\n",
    "         '\\nEach separate color of region indicates extracted region'\n",
    "         % (n_regions_extracted, 'all'))\n",
    "plot_prob_atlas(regions_extracted_img, view_type='filled_contours',\n",
    "                         title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
