{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Group analysis of resting-state fMRI with ICA: CanICA\n",
    "=====================================================\n",
    "\n",
    "An example applying CanICA to resting-state data. This example applies it\n",
    "to 30 subjects of the ADHD200 datasets. Then it plots a map with all the\n",
    "components together and an axial cut for each of the components separately.\n",
    "\n",
    "CanICA is an ICA method for group-level analysis of fMRI data. Compared\n",
    "to other strategies, it brings a well-controlled group model, as well as a\n",
    "thresholding algorithm controlling for specificity and sensitivity with\n",
    "an explicit model of the signal. The reference papers are:\n",
    "\n",
    "    * G. Varoquaux et al. \"A group model for stable multi-subject ICA on\n",
    "      fMRI datasets\", NeuroImage Vol 51 (2010), p. 288-299\n",
    "\n",
    "    * G. Varoquaux et al. \"ICA-based sparse features recovery from fMRI\n",
    "      datasets\", IEEE ISBI 2010, p. 1177\n",
    "\n",
    "Pre-prints for both papers are available on hal\n",
    "(http://hal.archives-ouvertes.fr)\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The use of the attribute `components_img_` from decomposition\n",
    "    estimators is implemented from version 0.4.1.\n",
    "    For older versions, unmask the deprecated attribute `components_`\n",
    "    to get the components image using attribute `masker_` embedded in\n",
    "    estimator.\n",
    "    See the `section Inverse transform: unmasking data <unmasking_step>`.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 load the ADHD200 data\n",
    "-------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/share/TmpData/Qinglin/Download/NYU/0010084/sfnwmrda0010084_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/1737393/sfnwmrda1737393_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/0010072/sfnwmrda0010072_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/4084645/sfnwmrda4084645_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/1992284/sfnwmrda1992284_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/4060823/sfnwmrda4060823_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/9750701/sfnwmrda9750701_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/4154672/sfnwmrda4154672_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/0010021/sfnwmrda0010021_session_1_rest_1.nii.gz', '/home/share/TmpData/Qinglin/Download/NYU/3679455/sfnwmrda3679455_session_1_rest_1.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "func_filenames=[]\n",
    "for x in os.listdir('/home/share/TmpData/Qinglin/Download/NYU'):\n",
    "    file='/home/share/TmpData/Qinglin/Download/NYU/'+str(x)+'/sfnwmrda'+str(x)+'_session_1_rest_1.nii.gz'\n",
    "    #print(file)\n",
    "    if os.path.isfile(file):\n",
    "        func_filenames.append(file)   \n",
    "func_filenames=func_filenames[:1]\n",
    "print(func_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/storage/ADHD200/NYU/0010012/sfnwmrda0010012_session_1_rest_1.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "func_filenames=[]\n",
    "for x in os.listdir('/storage/ADHD200/NYU'):\n",
    "    file='/storage/ADHD200/NYU/'+str(x)+'/sfnwmrda'+str(x)+'_session_1_rest_1.nii.gz'\n",
    "    #print(file)\n",
    "    if os.path.isfile(file):\n",
    "        func_filenames.append(file)   \n",
    "func_filenames=func_filenames[:1]\n",
    "print(func_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 apply CanICA on the data\n",
    "---------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultiNiftiMasker.fit] Loading data from [/storage/ADHD200/NYU/0010001/sfnwmrda0010001_session_1_rest_1.nii.gz]\n",
      "[MultiNiftiMasker.fit] Computing mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "/storage/ADHD200/NYU/0010001/sfnwmrda0010001_session_1_rest_1.nii.gz\n",
      "[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/storage/ADHD200/NYU/0010001/sfnwmrda0010001_session_1_rest_1.nii.gz')\n",
      "[MultiNiftiMasker.transform_single_imgs] Smoothing images\n",
      "[MultiNiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "(20, 52858)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.decomposition import CanICA\n",
    "\n",
    "canica = CanICA(n_components=20,\n",
    "                memory=\"nilearn_cache\", memory_level=2,\n",
    "                threshold=3., verbose=10, random_state=0,mask_strategy='background')\n",
    "data=canica.prepare_data('/storage/ADHD200/NYU/0010001/sfnwmrda0010001_session_1_rest_1.nii.gz')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.utils.extmath.randomized_svd...\n",
      "randomized_svd(array([[-8.125543e-04, ..., -1.685887e-05],\n",
      "       ...,\n",
      "       [-6.170593e-03, ..., -3.227540e-03]], dtype=float32), n_iter=3, transpose=True, random_state=0, n_components=20)\n",
      "___________________________________________________randomized_svd - 0.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=209652396)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 23.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=398764591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   48.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 25.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=924231285)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 25.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=1478610112)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 26.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=441365315)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 26.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=1537364731)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 25.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=192771779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 26.1s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=1491434855)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 25.9s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=1819583497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________fastica - 25.6s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.decomposition.fastica_.fastica...\n",
      "fastica(array([[ 6.848087e-03, ..., -2.125619e-05],\n",
      "       ...,\n",
      "       [-3.494941e-03, ..., -4.030404e-03]]), fun='cube', whiten=True, random_state=530702035)\n",
      "_________________________________________________________fastica - 25.9s, 0.4min\n",
      "(20, 52831)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/fastica_.py:121: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "components_img=canica._raw_fit2(data)\n",
    "print(components_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 plot each ICA component separately\n",
    "-----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=canica.masker_.mask_img_, standardize=True)\n",
    "masker.fit()\n",
    "\n",
    "components_img = canica.thresholding(components_img)\n",
    "components_img = masker.inverse_transform(components_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 58, 47)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canica.masker_.mask_img_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 525.6x187.2 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "\n",
    "\n",
    "plot_stat_map(canica.masker_.mask_img_,display_mode=\"ortho\", \n",
    "              cut_coords=None, colorbar='bwr',bg_img='/home/share/TmpData/Qinglin/bin/fMRI-Toolbox/templates/MNI152_T1_2mm_brain.nii.gz')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Extract regions from networks\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index (1159) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d0412a30a21b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                             standardize=True, min_region_size=5000)\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Just call fit() to process for regions extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# Extracted regions are stored in regions_img_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mregions_extracted_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregions_img_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nilearn-deep/nilearn/regions/region_extractor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_region_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                                                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                                                            self.smoothing_fwhm)\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaps_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregions_img_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nilearn-deep/nilearn/regions/region_extractor.py\u001b[0m in \u001b[0;36mconnected_regions\u001b[0;34m(maps_img, min_region_size, extract_type, smoothing_fwhm, mask_img)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# Assign -1 to values which are 0. to indicate to ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mseeds_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_3d\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mrw_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_random_walker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;31m# Now simply replace \"-1\" with \"0\" for regions separation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mrw_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrw_maps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nilearn-deep/nilearn/_utils/segmentation.py\u001b[0m in \u001b[0;36m_random_walker\u001b[0;34m(data, labels, beta, tol, copy, spacing)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mlap_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_laplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mlap_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_buildAB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlap_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# We solve the linear system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nilearn-deep/nilearn/_utils/segmentation.py\u001b[0m in \u001b[0;36m_buildAB\u001b[0;34m(lap_sparse, labels)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mseeds_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# The following two lines take most of the time in this function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlap_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munlabeled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mlap_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlap_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munlabeled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mnlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# [[1,2],??]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# [[1,2],j] or [[1,2],1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mextracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mextractor\u001b[0;34m(indices, N)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mmin_indx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_indx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mcheck_bounds\u001b[0;34m(indices, N)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mmax_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmax_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mmin_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index (1159) out of range"
     ]
    }
   ],
   "source": [
    "# Import Region Extractor algorithm from regions module\n",
    "# threshold=0.5 indicates that we keep nominal of amount nonzero voxels across all\n",
    "# maps, less the threshold means that more intense non-voxels will be survived.\n",
    "from nilearn.regions import RegionExtractor\n",
    "\n",
    "extractor = RegionExtractor(components_img, threshold=0.5,\n",
    "                            thresholding_strategy='ratio_n_voxels',\n",
    "                            extractor='local_regions',\n",
    "                            standardize=True, min_region_size=5000)\n",
    "# Just call fit() to process for regions extraction\n",
    "extractor.fit()\n",
    "# Extracted regions are stored in regions_img_\n",
    "regions_extracted_img = extractor.regions_img_\n",
    "# Each region index is stored in index_\n",
    "regions_index = extractor.index_\n",
    "# Total number of regions extracted\n",
    "n_regions_extracted = regions_extracted_img.shape[-1]\n",
    "\n",
    "from nilearn.plotting import plot_prob_atlas\n",
    "# Visualization of region extraction results\n",
    "title = ('%d regions are extracted from %s components.'\n",
    "         '\\nEach separate color of region indicates extracted region'\n",
    "         % (n_regions_extracted, 'all'))\n",
    "plot_prob_atlas(regions_extracted_img, view_type='filled_contours',\n",
    "                         title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Region signals extraction\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to do subjects timeseries signals extraction and then estimating\n",
    "# correlation matrices on those signals.\n",
    "# To extract timeseries signals, we call transform() from RegionExtractor object\n",
    "# onto each subject functional data stored in func_filenames.\n",
    "# To estimate correlation matrices we import connectome utilities from nilearn\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "confounds = adhd_dataset.confounds\n",
    "phenotypic = adhd_dataset.phenotypic\n",
    "adhd_time_series = []\n",
    "all_time_series = []\n",
    "site_names = []\n",
    "adhd_labels = []  # 1 if ADHD, 0 if control\n",
    "# Initializing ConnectivityMeasure object with kind='correlation'\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "for filename, confound, phenotypic in zip(func_filenames, confounds,phenotypic):\n",
    "    time_series = extractor.transform(filename, confounds=confound)   \n",
    "    all_time_series.append(time_series)\n",
    "    is_adhd = phenotypic['adhd']\n",
    "    if is_adhd:\n",
    "        adhd_time_series.append(time_series)\n",
    "    site_names.append(phenotypic['site'])\n",
    "    adhd_labels.append(is_adhd)        \n",
    "print('Data has {0} ADHD subjects.'.format(len(adhd_time_series)))        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3  Correlation coefficients\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix plotting from Nilearn: nilearn.plotting.plot_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def plot_matrices(matrices, matrix_kind):\n",
    "    n_matrices = len(matrices)\n",
    "    fig = plt.figure(figsize=(n_matrices * 4, 4))\n",
    "    for n_subject, matrix in enumerate(matrices):\n",
    "        plt.subplot(1, n_matrices, n_subject + 1)\n",
    "        matrix = matrix.copy()  # avoid side effects\n",
    "        # Set diagonal to zero, for better visualization\n",
    "        np.fill_diagonal(matrix, 0)\n",
    "        vmax = np.max(np.abs(matrix))\n",
    "        title = '{0}, subject {1}'.format(matrix_kind, n_subject)\n",
    "        plotting.plot_matrix(matrix, vmin=-vmax, vmax=vmax, cmap='RdBu_r',\n",
    "                             title=title, figure=fig, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrices = correlation_measure.fit_transform(adhd_time_series)\n",
    "        \n",
    "from nilearn import plotting\n",
    "plot_matrices(correlation_matrices[:4], 'correlation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 group-sparse precision matrices\n",
    "------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import GroupSparseCovarianceCV\n",
    "gsc = GroupSparseCovarianceCV(verbose=2)\n",
    "gsc.fit(adhd_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrices_2(cov, prec, title, labels=None):\n",
    "    \"\"\"Plot covariance and precision matrices, for a given processing. \"\"\"\n",
    "\n",
    "    prec = prec.copy()  # avoid side effects\n",
    "\n",
    "    # Put zeros on the diagonal, for graph clarity.\n",
    "    size = prec.shape[0]\n",
    "    prec[list(range(size)), list(range(size))] = 0\n",
    "    span = max(abs(prec.min()), abs(prec.max()))\n",
    "\n",
    "    # Display covariance matrix\n",
    "    plotting.plot_matrix(cov, cmap=plotting.cm.bwr,\n",
    "                         vmin=-1, vmax=1, title=\"%s / covariance\" % title,\n",
    "                         labels=labels)\n",
    "    # Display precision matrix\n",
    "    plotting.plot_matrix(prec, cmap=plotting.cm.bwr,\n",
    "                         vmin=-span, vmax=span, title=\"%s / precision\" % title,\n",
    "                         labels=labels)\n",
    "\n",
    "title = \"GroupSparseCovariance\"\n",
    "plot_matrices_2(gsc.covariances_[..., 0],\n",
    "              gsc.precisions_[..., 0], title)\n",
    "\n",
    "from nilearn.plotting import find_cuts\n",
    "regions_img = regions_extracted_img\n",
    "coords_connectome = find_cuts.find_probabilistic_atlas_cut_coords(regions_img)\n",
    "\n",
    "plotting.plot_connectome(-gsc.precisions_[..., 0],\n",
    "                         coords_connectome, edge_threshold='90%',\n",
    "                         title=title,\n",
    "                         display_mode=\"lzr\",\n",
    "                         edge_vmax=.5, edge_vmin=-.5)\n",
    "\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import html_connectome\n",
    "view = html_connectome.view_connectome(-gsc.precisions_[..., 0], coords_connectome, threshold='95%')\n",
    "view.open_in_browser()\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 classification\n",
    "----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_biomarkers = {}\n",
    "\n",
    "conn_measure = ConnectivityMeasure(kind='correlation', vectorize=True)\n",
    "connectivity_biomarkers = conn_measure.fit_transform(all_time_series)\n",
    "\n",
    "# For each kind, all individual coefficients are stacked in a unique 2D matrix.\n",
    "print('{0} correlation biomarkers for each subject.'.format(\n",
    "    connectivity_biomarkers.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "classes = ['{0}{1}'.format(site_name, adhd_label)\n",
    "           for site_name, adhd_label in zip(site_names, adhd_labels)]\n",
    "cv = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "mean_scores = []\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    cv_scores = cross_val_score(clf,\n",
    "                                connectivity_biomarkers,\n",
    "                                y=adhd_labels,\n",
    "                                cv=cv,\n",
    "                                groups=adhd_labels,\n",
    "                                scoring='accuracy',\n",
    "                                )\n",
    "    mean_scores.append(cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import show\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "positions = np.arange(len(names)) * .1 + .1\n",
    "plt.barh(positions, mean_scores, align='center', height=.05)\n",
    "yticks = [name.replace(' ', '\\n') for name in names]\n",
    "plt.yticks(positions, yticks)\n",
    "plt.xlabel('Classification accuracy')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D map\n",
    "----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting, datasets     \n",
    "view = plotting.view_img_on_surf(cur_img, threshold='90%', surf_mesh='fsaverage')   \n",
    "view.open_in_browser() \n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
