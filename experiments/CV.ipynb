{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "def build_model(data):\n",
    "   \n",
    "    # this is the size of our encoded representations\n",
    "    encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "    # this is our input placeholder\n",
    "    original_dim=data.shape[1]\n",
    "    input_img = Input(shape=(original_dim,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "\n",
    "    encoded = Dense(256, activation='tanh',\n",
    "                    activity_regularizer=regularizers.l1(2*10e-5))(input_img)\n",
    "    encoded = Dense(128, activation='tanh',\n",
    "                    activity_regularizer=regularizers.l1(2*10e-5))(encoded)\n",
    "    encoded = Dense(32, activation='tanh',\n",
    "                    activity_regularizer=regularizers.l1(2*10e-5))(encoded)\n",
    "\n",
    "    decoded = Dense(128, activation='tanh')(encoded)\n",
    "    decoded = Dense(256, activation='tanh')(decoded)\n",
    "    decoded = Dense(original_dim, activation='tanh')(decoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "\n",
    "    # this model maps an input to its encoded representation\n",
    "    encoder = Model(input_img, encoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    autoencoder.fit(data, data,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    shuffle=True)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decomposition import CanICA\n",
    "def prepare_data(func_filenames):\n",
    "    canica = CanICA(n_components=20, smoothing_fwhm=6.,\n",
    "                    memory=\"nilearn_cache\", memory_level=2,\n",
    "                    threshold=3., verbose=10, random_state=0)\n",
    "    data=canica.prepare_data(func_filenames)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "def corr(all_time_series):\n",
    "    connectivity_biomarkers = {}\n",
    "    conn_measure = ConnectivityMeasure(kind='correlation', vectorize=True)\n",
    "    connectivity_biomarkers = conn_measure.fit_transform(all_time_series)\n",
    "    return connectivity_biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify(train_X,train_Y, test_X, test_Y):\n",
    "    names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "             \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "             \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(kernel=\"linear\", C=0.025),\n",
    "        SVC(gamma=2, C=1),\n",
    "        GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "        DecisionTreeClassifier(max_depth=5),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "        MLPClassifier(alpha=1),\n",
    "        AdaBoostClassifier(),\n",
    "        GaussianNB(),\n",
    "        QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(train_X, train_Y) \n",
    "        score=clf.score(test_X,test_Y)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def CV(X,Y):\n",
    "    \n",
    "    # define 10-fold cross validation test harness\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    \n",
    "    # trick. split(Y,Y) instead of split(X,Y) due to X is already concatnated \n",
    "    for train,test in kfold.split(Y,Y):   \n",
    "        #indexing of specific subjects\n",
    "        train_X = [X[i*20:i*20+19] for i in train]    \n",
    "\n",
    "        train_Y = [Y[i] for i in train]\n",
    "        test_Y = [Y[i] for i in test]\n",
    "\n",
    "        #concat all subjects\n",
    "        model=build_model(np.vstack(train_X))\n",
    "\n",
    "        train_D = [model.predict(X[i*20:i*20+19]) for i in train]\n",
    "        test_D = [model.predict(X[i*20:i*20+19]) for i in test]\n",
    "\n",
    "        #Release GPU memory after model is used\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        \n",
    "        train_FC=corr(train_D)\n",
    "        test_FC=corr(test_D)\n",
    "\n",
    "        score=classify(train_FC,train_Y, test_FC, test_Y)\n",
    "        cvscores.append(score)\n",
    "    return cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/Documents/nilearn-deep/nilearn/datasets/func.py:503: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultiNiftiMasker.fit] Loading data from [/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz, /home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.g\n",
      "[MultiNiftiMasker.fit] Computing mask\n",
      "[MultiNiftiMasker.transform] Resampling mask\n",
      "[CanICA] Loading data\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010128/0010128_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0021019/0021019_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0023008/0023008_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0023012/0023012_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027011/0027011_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027018/0027018_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027034/0027034_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/0027037/0027037_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1019436/1019436_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1206380/1206380_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1418396/1418396_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1517058/1517058_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1552181/1552181_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1562298/1562298_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/1679142/1679142_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/2014113/2014113_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/2497695/2497695_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/2950754/2950754_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3007585/3007585_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3154996/3154996_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3205761/3205761_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3520880/3520880_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3624598/3624598_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3699991/3699991_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3884955/3884955_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3902469/3902469_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/3994098/3994098_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/4016887/4016887_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/4046678/4046678_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/4134561/4134561_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/4164316/4164316_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/4275075/4275075_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/6115230/6115230_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/7774305/7774305_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/8409791/8409791_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/8697774/8697774_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/9744150/9744150_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "/home/share/TmpData/Qinglin/nilearn_data/adhd/data/9750701/9750701_rest_tshift_RPI_voreg_mni.nii.gz\n",
      "Epoch 1/10\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 8.6988\n",
      "Epoch 2/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 7.5523\n",
      "Epoch 3/10\n",
      "608/608 [==============================] - 2s 2ms/step - loss: 6.9388\n",
      "Epoch 4/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.5430\n",
      "Epoch 5/10\n",
      "608/608 [==============================] - 2s 2ms/step - loss: 6.3256\n",
      "Epoch 6/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 5.9713\n",
      "Epoch 7/10\n",
      "608/608 [==============================] - 2s 2ms/step - loss: 5.9048\n",
      "Epoch 8/10\n",
      "608/608 [==============================] - 2s 2ms/step - loss: 5.6420\n",
      "Epoch 9/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.5045\n",
      "Epoch 10/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "608/608 [==============================] - 3s 5ms/step - loss: 8.7017\n",
      "Epoch 2/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 7.4495\n",
      "Epoch 3/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 6.7840\n",
      "Epoch 4/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.3865\n",
      "Epoch 5/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.0834\n",
      "Epoch 6/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.8865\n",
      "Epoch 7/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 5.7119\n",
      "Epoch 8/10\n",
      "608/608 [==============================] - 2s 2ms/step - loss: 5.5468\n",
      "Epoch 9/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 5.3655\n",
      "Epoch 10/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 5.3263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "608/608 [==============================] - 3s 5ms/step - loss: 8.7134\n",
      "Epoch 2/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 7.5378\n",
      "Epoch 3/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 6.8796\n",
      "Epoch 4/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 6.5018\n",
      "Epoch 5/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.1446\n",
      "Epoch 6/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.9572\n",
      "Epoch 7/10\n",
      "608/608 [==============================] - 1s 2ms/step - loss: 5.7263\n",
      "Epoch 8/10\n",
      "608/608 [==============================] - 2s 2ms/step - loss: 5.5437\n",
      "Epoch 9/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.4314\n",
      "Epoch 10/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "608/608 [==============================] - 3s 6ms/step - loss: 8.7533\n",
      "Epoch 2/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 7.6047\n",
      "Epoch 3/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.9405\n",
      "Epoch 4/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.5062\n",
      "Epoch 5/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.2005\n",
      "Epoch 6/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.9394\n",
      "Epoch 7/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.7549\n",
      "Epoch 8/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.5889\n",
      "Epoch 9/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.4894\n",
      "Epoch 10/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.3548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "608/608 [==============================] - 3s 6ms/step - loss: 8.6060\n",
      "Epoch 2/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 7.4351\n",
      "Epoch 3/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.8101\n",
      "Epoch 4/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.4287\n",
      "Epoch 5/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 6.0640\n",
      "Epoch 6/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.8205\n",
      "Epoch 7/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.7286\n",
      "Epoch 8/10\n",
      "608/608 [==============================] - 2s 2ms/step - loss: 5.5225\n",
      "Epoch 9/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.4668\n",
      "Epoch 10/10\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 5.2810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "adhd_dataset = datasets.fetch_adhd(n_subjects=40,data_dir='/home/share/TmpData/Qinglin/nilearn_data/')\n",
    "X = prepare_data(adhd_dataset.func)  # list of 4D nifti files for each subject  \n",
    "Y = adhd_dataset.phenotypic['adhd']\n",
    "\n",
    "cvscores=CV(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5, 0.5, 0.5, 0.875, 0.375, 0.25, 0.25, 0.75, 0.375, 0.625],\n",
       " [0.5, 0.625, 0.625, 0.375, 0.625, 0.5, 0.75, 0.875, 0.5, 0.5],\n",
       " [0.75, 0.625, 0.625, 0.5, 0.625, 0.25, 0.625, 0.625, 0.75, 0.625],\n",
       " [0.25, 0.5, 0.375, 0.5, 0.625, 0.875, 0.375, 0.5, 0.25, 0.5],\n",
       " [0.25, 0.625, 0.375, 0.375, 0.375, 0.375, 0.5, 0.5, 0.25, 0.5]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
